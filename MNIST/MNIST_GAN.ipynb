{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://www.datacamp.com/tutorial/generative-adversarial-networks\n",
        "# https://colab.research.google.com/drive/1PErY9XmsMTGOYApgh1xmErXkmXbMSNjY\n",
        "\n",
        "# https://medium.datadriveninvestor.com/generative-adversarial-network-gan-using-keras-ce1c05cfdfd3"
      ],
      "metadata": {
        "id": "4l37QC8WvD6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAUuqSICsNiq",
        "outputId": "06c7b893-2c4a-4c68-e7a9-01f64074e973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQmhdgJkm1oo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a3094a-1c23-4065-d817-ee7935a32543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist_dataset():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "  # Convert shape from (60000, 28, 28) to (60000, 784)\n",
        "  x_train = x_train.reshape(60000, 784)\n",
        "  return (x_train, y_train, x_test, y_test)\n",
        "\n",
        "(X_train, y_train,X_test, y_test)=load_mnist_dataset()\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "gGjaQQywnzRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, LeakyReLU\n",
        "from keras import initializers\n",
        "\n",
        "def generator_model(latent_dimension):\n",
        "\n",
        "  generator = Sequential()\n",
        "  generator.add(Dense(256, input_dim=latent_dimension))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "\n",
        "  generator.add(Dense(512))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "\n",
        "  generator.add(Dense(1024))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "\n",
        "  generator.add(Dense(784, activation='tanh'))\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "  return generator\n",
        "\n",
        "generator = generator_model(100)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "xZ-sqrD8oxx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625f6ed9-479b-4370-b04a-e79c5570584f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1486352 (5.67 MB)\n",
            "Trainable params: 1486352 (5.67 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_model():\n",
        "\n",
        "  discriminator = Sequential()\n",
        "  discriminator.add(Dense(1024, input_dim=784))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "\n",
        "  discriminator.add(Dense(512))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "\n",
        "  discriminator.add(Dense(256))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "  return discriminator\n",
        "\n",
        "discriminator = discriminator_model()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "pU2gniyOpbt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0fe432-bbc0-430a-f0e3-e6b6dec4e344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1460225 (5.57 MB)\n",
            "Trainable params: 1460225 (5.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "\n",
        "def gan_model(generator, discriminator, latent_dimension):\n",
        "\n",
        "  discriminator.trainable = False\n",
        "  # The , after latent_dimension is to indicate to Python that it is a tuple and not a value\n",
        "  gan_input = Input(shape=(latent_dimension,))\n",
        "\n",
        "  x = generator(gan_input)\n",
        "  gan_output = discriminator(x)\n",
        "\n",
        "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "  return gan\n",
        "\n",
        "gan = gan_model(generator, discriminator, 100)\n",
        "gan.summary()"
      ],
      "metadata": {
        "id": "_BBPRQ_eqFDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35474caa-7ffc-43db-e020-d154ce5117ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 784)               1486352   \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 1)                 1460225   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2946577 (11.24 MB)\n",
            "Trainable params: 1486352 (5.67 MB)\n",
            "Non-trainable params: 1460225 (5.57 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(10)\n",
        "\n",
        "def plot_generated_images(epoch, generator, latent_dimension, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "\n",
        "  noise = np.random.normal(0, 1, size=[examples, latent_dimension])\n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "  plt.figure(figsize=figsize)\n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0], dim[1], i+1)\n",
        "    plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('/content/drive/MyDrive/Colab Notebooks/gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "vxX69mbxrGkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(epochs, batch_size):\n",
        "\n",
        "  X_train, y_train, X_test, y_test = load_mnist_dataset()\n",
        "  batch_count = X_train.shape[0] / batch_size\n",
        "\n",
        "  generator = generator_model(latent_dimension=100)\n",
        "  discriminator = discriminator_model()\n",
        "\n",
        "  gan = gan_model(generator, discriminator, 100)\n",
        "\n",
        "  for e in range(1, epochs+1):\n",
        "    print(\"Epoch %d\" %e)\n",
        "\n",
        "    for _ in tqdm(range(batch_size)):\n",
        "      # Generate random noise\n",
        "      noise= np.random.normal(0,1, [batch_size, 100])\n",
        "      generated_images = generator.predict(noise)\n",
        "      # Get a random set of real images\n",
        "      real_images = X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
        "\n",
        "      X= np.concatenate([real_images, generated_images])\n",
        "      # Initialize the first half of labels as real and rest generated\n",
        "      y_dis=np.zeros(2*batch_size)\n",
        "      y_dis[:batch_size]=0.9\n",
        "\n",
        "      # Pre train discriminator on fake and real data before starting the GAN\n",
        "      discriminator.trainable = True\n",
        "      discriminator.train_on_batch(X, y_dis)\n",
        "\n",
        "      # Staging the noised input of Generator as real data\n",
        "      noise= np.random.normal(0,1, [batch_size, 100])\n",
        "      y_gen = np.ones(batch_size)\n",
        "\n",
        "      # Fix the weights of discriminator for the GAN training\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "      if e == 1 or e % 20 == 0:\n",
        "        plot_generated_images(e, generator, 100)"
      ],
      "metadata": {
        "id": "M8eznmjoqXn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(400, 128)"
      ],
      "metadata": {
        "id": "HafHrXL37HWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}